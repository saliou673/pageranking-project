= Projet page Ranking Master 2 ALMA Nantes Université

== Auteurs
. Mamadou Saliou DIALLO (18C764T)
. Ibrahima DIALLO
. Mamadou DIALLO
. Yassine El Kamel

== Structure du projet
- link:./[pageranking-project] : Racine du projet.
- link:data[] contient un dataset légé.
- link:ranker/spark[]: contient le code page ranking avec spark.
- link:ranker/pig[]: contient le code page ranking avec pig.
- link:wikipedia-scraper[]: contient code du scraper pour wikipédia.
```
== Dataset
Pour l'obtention du dataset, on a préféré créer notre propre dataset
en faisant du scraping sur https://www.wikipédia.com[Wikipedia] via https://www.dbpedia.com[DBPedia].

== Première étape: Requête SPARQL
Pour accéder aux différents articles de https://www.wikipédia.com[Wikipedia], nous avons écris une requête SPARQL qui liste tous articles.

[sparql]
```
SELECT ?sitelink
WHERE {
  ?item wdt:P21 wd:Q6581097;
        wdt:P31
                 wd:Q5.
  ?sitelink schema:about ?item;
  schema:isPartOf <https://en.wikipedia.org/>.
} 

LIMIT 10000  OFFSET 0
```

Cette requête a ensuite été envoyé via l'API https://wikidata.demo.openlinksw.com/sparql afin lire progressivement les urls des différentes pages.

Ensuite chaque url est scrapé avec https://pypi.org/project/beautifulsoup4[BeautifulSoup 4] pour récupére toutes les adresses et sont stockés sous le format:

```
URL1    1   { (URL2), (URL3)}

...

URLN    1   { (URLX), (URLY), ...}
```

=== Format de la requête HTTP

[http]
```
GET https://wikidata.demo.openlinksw.com/sparql?default-graph-uri=http://www.wikidata.org/&query=requeteSparql&format=application/sparql-results+json&timeout=0&signal_void=on&signal_unconnected=on
```
== Uploader les données sur Google Cloud Storage
Pour éviter de restocker les données à chaque nouvelle éxécution des scripts *PIG* et *SPARK*. Les données sont stockées sur *Google Cloud Storage*. 

Le dataset de 1 Go est disponible https://storage.googleapis.com/dataset-pagerank/data.txt[ici].

== Lancer les scripts de pages ranking

Avant de lancer un script, il faut ouvrir le fichier correspondant et modifier le nom du cluster et assurez-vous d'ouvrir le terminal à la racine.

[bash]
```
gcloud ... --cluster=le-nom-de-votre-cluster
```
=== Lancement de PIG
[bash]
```
./run-pig.sh
```
=== Lancement de SPARK
[bash]
```
./run-spark.sh
```

== Comparaison PIG et SPARK
Dans le tableau ci-après la durée en temps de l'éxécution de chaque script
sur *10 itérations* sur le cluster avec *2 noeuds* et *5 noeuds*.


|===
||2 Noeuds |5 Noeuds

|*SPARK*
|7 minutes 25 secondes
|5 minutes 47 secondes

|*PIG*
|19 minutes 30 secondes
|15 minutes 24 secondes
|===

On peut clairement voir que *SPARK* est plus rapide que *PIG*.

Cette différence de performances pourrait s'expliquer par le fait qu'avec *PIG*,
à chaque itération l'ensemble des données sont écrit sur le disque (ce qui est couteux en temps) alors que *SPARK* manipule visiblement données en mémoire RAM.

=== Plus de noeud pour plus de rapidité ?
En se basant sur les résultats de performance précédent, on peut espérer réduire le temps d'éxécution. 

Mais à un certains niveau, l'augmentation du nombre de noeuds n'aura pas d'effet.

NOTE: Nous n'avons pas pu tester au délà de 5 noeuds suites à des limitations de credit *Google cloud*.